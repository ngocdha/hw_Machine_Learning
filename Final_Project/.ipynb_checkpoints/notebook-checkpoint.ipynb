{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngoc Ha\n",
    "# CSCI 547\n",
    "## Project: predict blood donation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dc": {
     "key": "10"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency (months)</th>\n",
       "      <th>Frequency (times)</th>\n",
       "      <th>Monetary (c.c. blood)</th>\n",
       "      <th>Time (months)</th>\n",
       "      <th>whether he/she donated blood in March 2007</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>12500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3250</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4000</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>5000</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6000</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)  \\\n",
       "0                 2                 50                  12500             98   \n",
       "1                 0                 13                   3250             28   \n",
       "2                 1                 16                   4000             35   \n",
       "3                 2                 20                   5000             45   \n",
       "4                 1                 24                   6000             77   \n",
       "\n",
       "   whether he/she donated blood in March 2007  \n",
       "0                                           1  \n",
       "1                                           1  \n",
       "2                                           1  \n",
       "3                                           1  \n",
       "4                                           0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Read in dataset\n",
    "transfusion = pd.read_csv('datasets/transfusion.csv')\n",
    "\n",
    "# Print out the first rows of our dataset\n",
    "transfusion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Summary of data to look for non-numeric data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dc": {
     "key": "17"
    },
    "scrolled": true,
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 748 entries, 0 to 747\n",
      "Data columns (total 5 columns):\n",
      "Recency (months)                              748 non-null int64\n",
      "Frequency (times)                             748 non-null int64\n",
      "Monetary (c.c. blood)                         748 non-null int64\n",
      "Time (months)                                 748 non-null int64\n",
      "whether he/she donated blood in March 2007    748 non-null int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 29.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Print a concise summary of transfusion DataFrame\n",
    "transfusion.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Rename target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dc": {
     "key": "24"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency (months)</th>\n",
       "      <th>Frequency (times)</th>\n",
       "      <th>Monetary (c.c. blood)</th>\n",
       "      <th>Time (months)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>12500</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3250</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4000</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>5000</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>6000</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)  \\\n",
       "0                 2                 50                  12500             98   \n",
       "1                 0                 13                   3250             28   \n",
       "2                 1                 16                   4000             35   \n",
       "3                 2                 20                   5000             45   \n",
       "4                 1                 24                   6000             77   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename target column as 'target' for brevity \n",
    "transfusion.rename(\n",
    "    columns={'whether he/she donated blood in March 2007': 'target'},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "\n",
    "# Print out the first 2 rows\n",
    "transfusion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Proportions of target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dc": {
     "key": "31"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.762032\n",
       "1    0.237968\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print target incidence proportions, rounding output to 3 decimal places\n",
    "transfusion.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Splitting data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dc": {
     "key": "38"
    },
    "scrolled": true,
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recency (months)</th>\n",
       "      <th>Frequency (times)</th>\n",
       "      <th>Monetary (c.c. blood)</th>\n",
       "      <th>Time (months)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1250</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3250</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>3000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2000</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)\n",
       "132                 2                  2                    500             10\n",
       "294                11                  5                   1250             35\n",
       "522                 4                 13                   3250             39\n",
       "291                16                 12                   3000             50\n",
       "106                 0                  8                   2000             59"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import train_test_split method\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split transfusion DataFrame into\n",
    "# X_train, X_test, y_train and y_test datasets,\n",
    "# stratifying on the `target` column\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    transfusion.drop(columns='target'),\n",
    "    transfusion.target,\n",
    "    test_size=0.25,\n",
    "    random_state=1,\n",
    "    stratify=transfusion.target\n",
    ")\n",
    "\n",
    "# Print out the first 2 rows of X_train\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.93525944 -0.60457944 -0.60457944 -0.98853267]\n",
      " [ 0.20617757 -0.08807832 -0.08807832  0.02693431]]\n",
      "[[-0.8084331  -0.08807832 -0.08807832 -0.3386338 ]\n",
      " [ 0.84030924 -0.4324124  -0.4324124  -0.62296456]]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_std = std_scale.transform(X_train)\n",
    "X_test_std  = std_scale.transform(X_test) # Use training mean and std to standardize test set\n",
    "\n",
    "print(X_train_std[:2,:])\n",
    "print(X_test_std[:2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "dc": {
     "key": "45"
    },
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 3. TPOT AutoML\n",
    "<p><a href=\"https://github.com/EpistasisLab/tpot\">TPOT</a> is a Python Automated Machine Learning tool that optimizes machine learning pipelines using genetic programming. TPOT will automatically explore hundreds of possible pipelines to find the best one for our training set. The outcome of this search will be a <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">scikit-learn pipeline</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Parallel Genetic Algorithm (3 subprocesses) - 100 generations; population size: 100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (may take ~5 minutes to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "dc": {
     "key": "45"
    },
    "scrolled": false,
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=10100, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.7527359001640808\n",
      "Generation 2 - Current best internal CV score: 0.7528776097996344\n",
      "Generation 3 - Current best internal CV score: 0.7528776097996344\n",
      "Generation 4 - Current best internal CV score: 0.7528776097996344\n",
      "Generation 5 - Current best internal CV score: 0.7528776097996344\n",
      "Generation 6 - Current best internal CV score: 0.753230441848773\n",
      "Generation 7 - Current best internal CV score: 0.7543862561920017\n",
      "Generation 8 - Current best internal CV score: 0.7543862561920017\n",
      "Generation 9 - Current best internal CV score: 0.7581829129982344\n",
      "Generation 10 - Current best internal CV score: 0.7581829129982344\n",
      "Generation 11 - Current best internal CV score: 0.7581829129982344\n",
      "Generation 12 - Current best internal CV score: 0.7581829129982344\n",
      "Generation 13 - Current best internal CV score: 0.7581829129982344\n",
      "Generation 14 - Current best internal CV score: 0.7598150681461215\n",
      "Generation 15 - Current best internal CV score: 0.7598150681461215\n",
      "Generation 16 - Current best internal CV score: 0.7598150681461215\n",
      "Generation 17 - Current best internal CV score: 0.7598150681461215\n",
      "Generation 18 - Current best internal CV score: 0.7598150681461215\n",
      "Generation 19 - Current best internal CV score: 0.7598150681461215\n",
      "Generation 20 - Current best internal CV score: 0.7598150681461215\n",
      "Generation 21 - Current best internal CV score: 0.7602838479856263\n",
      "Generation 22 - Current best internal CV score: 0.7613872812094427\n",
      "Generation 23 - Current best internal CV score: 0.7613872812094427\n",
      "Generation 24 - Current best internal CV score: 0.7613872812094427\n",
      "Generation 25 - Current best internal CV score: 0.7618397698972255\n",
      "Generation 26 - Current best internal CV score: 0.7618397698972255\n",
      "Generation 27 - Current best internal CV score: 0.7618397698972255\n",
      "Generation 28 - Current best internal CV score: 0.7618397698972255\n",
      "Generation 29 - Current best internal CV score: 0.7618397698972255\n",
      "Generation 30 - Current best internal CV score: 0.7618397698972255\n",
      "Generation 31 - Current best internal CV score: 0.7618397698972255\n",
      "Generation 32 - Current best internal CV score: 0.7631099340948863\n",
      "Generation 33 - Current best internal CV score: 0.7631551829636646\n",
      "Generation 34 - Current best internal CV score: 0.7631551829636646\n",
      "Generation 35 - Current best internal CV score: 0.7631551829636646\n",
      "Generation 36 - Current best internal CV score: 0.7631551829636646\n",
      "Generation 37 - Current best internal CV score: 0.7631551829636646\n",
      "Generation 38 - Current best internal CV score: 0.7631551829636646\n",
      "Generation 39 - Current best internal CV score: 0.7642559659522724\n",
      "Generation 40 - Current best internal CV score: 0.7642559659522724\n",
      "Generation 41 - Current best internal CV score: 0.7642559659522724\n",
      "Generation 42 - Current best internal CV score: 0.7642559659522724\n",
      "Generation 43 - Current best internal CV score: 0.7642559659522724\n",
      "Generation 44 - Current best internal CV score: 0.7643012148210506\n",
      "Generation 45 - Current best internal CV score: 0.7643012148210506\n",
      "Generation 46 - Current best internal CV score: 0.7643012148210506\n",
      "Generation 47 - Current best internal CV score: 0.7643012148210506\n",
      "Generation 48 - Current best internal CV score: 0.7655728600325042\n",
      "Generation 49 - Current best internal CV score: 0.7655728600325042\n",
      "Generation 50 - Current best internal CV score: 0.7655728600325042\n",
      "Generation 51 - Current best internal CV score: 0.7655728600325042\n",
      "Generation 52 - Current best internal CV score: 0.7655728600325042\n",
      "Generation 53 - Current best internal CV score: 0.7655728600325042\n",
      "Generation 54 - Current best internal CV score: 0.7655728600325042\n",
      "Generation 55 - Current best internal CV score: 0.7655728600325042\n",
      "Generation 56 - Current best internal CV score: 0.7655728600325042\n",
      "Generation 57 - Current best internal CV score: 0.7675735147964969\n",
      "Generation 58 - Current best internal CV score: 0.7675735147964969\n",
      "Generation 59 - Current best internal CV score: 0.7675735147964969\n",
      "Generation 60 - Current best internal CV score: 0.7675735147964969\n",
      "Generation 61 - Current best internal CV score: 0.7675735147964969\n",
      "Generation 62 - Current best internal CV score: 0.767684240064541\n",
      "Generation 63 - Current best internal CV score: 0.7682060246082134\n",
      "Generation 64 - Current best internal CV score: 0.7682060246082134\n",
      "Generation 65 - Current best internal CV score: 0.7682060246082134\n",
      "Generation 66 - Current best internal CV score: 0.7682060246082134\n",
      "Generation 67 - Current best internal CV score: 0.7682060246082134\n",
      "Generation 68 - Current best internal CV score: 0.7682490909303494\n",
      "Generation 69 - Current best internal CV score: 0.7682490909303494\n",
      "Generation 70 - Current best internal CV score: 0.7682490909303494\n",
      "Generation 71 - Current best internal CV score: 0.7682490909303494\n",
      "Generation 72 - Current best internal CV score: 0.7682490909303494\n",
      "Generation 73 - Current best internal CV score: 0.7686410529228587\n",
      "Generation 74 - Current best internal CV score: 0.7686410529228587\n",
      "Generation 75 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 76 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 77 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 78 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 79 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 80 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 81 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 82 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 83 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 84 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 85 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 86 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 87 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 88 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 89 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 90 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 91 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 92 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 93 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 94 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 95 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 96 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 97 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 98 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 99 - Current best internal CV score: 0.7710369045252765\n",
      "Generation 100 - Current best internal CV score: 0.7710369045252765\n",
      "\n",
      "Best pipeline: LogisticRegression(DecisionTreeClassifier(MaxAbsScaler(CombineDFs(CombineDFs(input_matrix, Binarizer(GaussianNB(input_matrix), threshold=0.55)), input_matrix)), criterion=gini, max_depth=5, min_samples_leaf=7, min_samples_split=13), C=0.1, dual=True, penalty=l2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict='TPOT light', crossover_rate=0.1, cv=5,\n",
       "        disable_update_check=True, early_stop=None, generations=100,\n",
       "        max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
       "        mutation_rate=0.9, n_jobs=3, offspring_size=None,\n",
       "        periodic_checkpoint_folder=None, population_size=100,\n",
       "        random_state=42, scoring='roc_auc', subsample=1.0,\n",
       "        template='RandomTree', use_dask=False, verbosity=2,\n",
       "        warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import TPOTClassifier and roc_auc_score\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "# Instantiate TPOTClassifier\n",
    "tpot = TPOTClassifier(\n",
    "    generations=100,\n",
    "    population_size=100,\n",
    "    verbosity=2,\n",
    "    scoring='roc_auc',\n",
    "    random_state=42,\n",
    "    disable_update_check=True,\n",
    "    config_dict='TPOT light',\n",
    "    n_jobs = 3\n",
    ")\n",
    "\n",
    "tpot.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Pipeline found by TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline steps:\n",
      "1. FeatureUnion(n_jobs=None,\n",
      "       transformer_list=[('featureunion', FeatureUnion(n_jobs=None,\n",
      "       transformer_list=[('functiontransformer', FunctionTransformer(accept_sparse=False, check_inverse=True,\n",
      "          func=<function copy at 0x00000207B7137D08>, inv_kw_args=None,\n",
      "          inverse_func=None, kw_args=None, pass_y='deprec...rgs=None,\n",
      "          inverse_func=None, kw_args=None, pass_y='deprecated',\n",
      "          validate=None))],\n",
      "       transformer_weights=None)\n",
      "2. MaxAbsScaler(copy=True)\n",
      "3. StackingEstimator(estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=7, min_samples_split=13,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'))\n",
      "4. LogisticRegression(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Print best pipeline steps\n",
    "print('\\nBest pipeline steps:', end='\\n')\n",
    "for idx, (name, transform) in enumerate(tpot.fitted_pipeline_.steps, start=1):\n",
    "    # Print idx and transform\n",
    "    print(f'{idx}. {transform}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the pipeline\n",
    "tpot.export('tpot_pipeline.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. TPOT model performance (AUC score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on training set 0.8272696929238986\n",
      "Loss on test set 0.7557902973395931\n"
     ]
    }
   ],
   "source": [
    "print('Loss on training set', tpot.score(X_train_std, y_train))\n",
    "print('Loss on test set', tpot.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Vanillia logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dc": {
     "key": "66"
    },
    "scrolled": true,
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on training set 0.7475932822710983\n",
      "Loss on test set 0.7778560250391237\n"
     ]
    }
   ],
   "source": [
    "# Importing modules\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Instantiate LogisticRegression\n",
    "logreg = linear_model.LogisticRegression(\n",
    "    solver='lbfgs',\n",
    "    random_state=42,\n",
    "    C=np.inf\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "logreg.fit(X_train_std, y_train)\n",
    "\n",
    "# AUC score for tpot model\n",
    "print('Loss on training set', roc_auc_score(y_train, logreg.predict_proba(X_train_std)[:, 1]))\n",
    "print('Loss on test set', roc_auc_score(y_test, logreg.predict_proba(X_test_std)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Logistic regression with polynomial features and regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_poly = preprocessing.PolynomialFeatures(2)\n",
    "X_train_poly = X_train_poly.fit_transform(X_train_std)\n",
    "X_test_poly = preprocessing.PolynomialFeatures(2)\n",
    "X_test_poly = X_test_poly.fit_transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on training set 0.7603471295060079\n",
      "Loss on test set 0.7836463223787168\n"
     ]
    }
   ],
   "source": [
    "# Instantiate LogisticRegression\n",
    "logreg2 = linear_model.LogisticRegression(\n",
    "    solver='liblinear',\n",
    "    random_state=42,\n",
    "    penalty = 'l2'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "logreg2.fit(X_train_poly, y_train)\n",
    "\n",
    "# AUC score for tpot model\n",
    "print('Loss on training set', roc_auc_score(y_train, logreg2.predict_proba(X_train_poly)[:, 1]))\n",
    "print('Loss on test set', roc_auc_score(y_test, logreg2.predict_proba(X_test_poly)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A \"vanilla\" logistic regression model outperformed the pipeline produced by TPOT after 100 generations with population size of 100.\n",
    "\n",
    "- The TPOT pipeline overfit the data, which was clearly shown by the large difference between training loss and test loss. There are several TPOT functions that can help with preventing overfitting, which will be studied in a future project.\n",
    "\n",
    "- We managed to improve our logistic model a little bit by creating 2nd-order features, and fit the logistic regression model with L2 regularization.\n",
    "\n",
    "- Final loss on test set: 0.7836, which is better than guessing everything to be 0 (0.7620)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
